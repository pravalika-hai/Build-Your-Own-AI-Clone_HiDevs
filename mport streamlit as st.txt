
import streamlit as st
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import requests

# --------- Load Vector Database ---------
@st.cache_resource
def load_vectorstore():
    loader = DirectoryLoader("docs/")
    docs = loader.load()
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(docs)
    embedding = OpenAIEmbeddings()
    db = FAISS.from_documents(chunks, embedding)
    return db.as_retriever()

retriever = load_vectorstore()

# --------- Groq Inference Function ---------
def call_groq_api(prompt):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer YOUR_GROQ_API_KEY"}
    payload = {
        "model": "llama3-70b-8192",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3
    }
    response = requests.post(url, headers=headers, json=payload)
    return response.json()["choices"][0]["message"]["content"]

# --------- Prompt Template ---------
def format_prompt(query, context):
    return f\"\"\"You are a helpful assistant.
Answer the question based only on the context provided.

Context:
{context}

Question: {query}\"\"\"

# --------- Generate Answer ---------
def generate_answer(query):
    docs = retriever.get_relevant_documents(query)
    context = "\n".join([doc.page_content for doc in docs])
    prompt = format_prompt(query, context)
    return call_groq_api(prompt)

# --------- Streamlit UI ---------
st.title("ðŸ§  RAG Chatbot with Groq + Arize")
query = st.text_input("Ask a question:")

if query:
    answer = generate_answer(query)
    st.write("### Answer")
    st.write(answer)

    # Arize Phoenix Logging (optional)
    try:
        import phoenix as px
        from phoenix.trace.span import Span
        with Span(name="qa-pipeline") as span:
            span.inputs["query"] = query
            span.outputs["answer"] = answer
            span.tags["source"] = "RAG Chatbot"
    except ImportError:
        st.warning("Phoenix not installed. Skipping evaluation logging.")
